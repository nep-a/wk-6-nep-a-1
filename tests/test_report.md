# üßæ CleanCity Test Report

**Date:** [18/11/2025]  
**Phase 3:** Test Design & Early Execution   

---

## Project Overview
The Clean City Project is a web-based sustainability platform enabling citizens to report waste, view cleanup events, and volunteer for environmental causes. The system includes a user interface, forms, event listings, and an admin dashboard.

---
1. Purpose & Scope
This document explains how we will test the CleanCity waste pickup scheduling system. Our goal is to make sure users can:
‚Ä¢	Submit pickup requests
‚Ä¢	Register/log in
‚Ä¢	Track recycling status
‚Ä¢	Give feedback
‚Ä¢	View awareness information
‚Ä¢	Admins can update request statuses
We‚Äôll test the app manually and with automated React tests to confirm it works smoothly, looks right on multiple devices, and stores data properly.
Scope
(In-scope):
‚Ä¢	Home Page: pickup request form and validation
‚Ä¢	User Registration & Login
‚Ä¢	Dashboard: listing, filtering, and status display
‚Ä¢	Feedback page submission, and request ID validation 
‚Ä¢	Awareness page: content and accessibility checks
‚Ä¢	Admin panel: update statuses, UI state, persistence via localStorage
‚Ä¢	Responsive layout on desktop and mobile viewports
‚Ä¢	Automated unit/integration tests with React Testing Library
Out-of-scope:
‚Ä¢	Backend API tests 
‚Ä¢	Advanced Security penetration testing
‚Ä¢	Performance load testing 
2. Test Objectives
We need to verify all functional requirements (submit requests, view requests, filter, update status). Validate form inputs and error messages. Confirm data persistence. Check accessibility Ensure UI responds on different screen sizes (mobile, tablet, desktop). Execute automated test suite and verify passing tests for key flows.
3. Test Approach & Strategy
Strategies used:
‚Ä¢	Manual Exploratory & Scripted Testing: Execute explicit test cases for forms, filtering, admin actions, and feedback.
‚Ä¢	Boundary Testing: Inputs with very long strings, invalid dates, missing required fields.
‚Ä¢	Accessibility Checks: Manual screen reader checks, keyboard navigation, and Lighthouse a11y audits.
‚Ä¢	Automated Tests: Use React Testing Library to validate core component logic and form validation behavior.
‚Ä¢	Data Persistence Checks: Use browser devtools to inspect localStorage after actions.
Test Types:
‚Ä¢	Functional tests (positive/negative)
‚Ä¢	Usability & Accessibility tests
‚Ä¢	Responsive tests
‚Ä¢	Regression tests after bug fixes
‚Ä¢	Automated unit/integration tests 
Environments:
‚Ä¢	Development: localhost:3000 (React dev server)
‚Ä¢	Browser targets: Chrome, Firefox, Edge, and Safari; ensuring desktop and mobile simulation
‚Ä¢	Node.js
4. Entry & Exit Criteria
Entry Criteria:
‚Ä¢	Application starts successfully.
‚Ä¢	Test data seeded / sample requests present (REQ001‚ÄìREQ005).
‚Ä¢	Test environment (browsers) available.
‚Ä¢	Test plan approved.
Exit Criteria:
‚Ä¢	All P0 and P1 test cases executed and passed OR have approved mitigations / accepted risks.
‚Ä¢	All P0 defects fixed and re-tested.
‚Ä¢	Test summary report completed and signed off by Test Manager.
5. Test Deliverables
‚Ä¢	Test Plan 
‚Ä¢	Test Cases & Execution Results 
‚Ä¢	GitHub Issues 
‚Ä¢	Test Summary Report
‚Ä¢	Automated test reports
‚Ä¢	Accessibility audit report (Lighthouse)
6. Test Schedule
‚Ä¢	Day 1: Setup + smoke tests (install/run)
‚Ä¢	Day 2: Manual functional tests ‚Äî Home & forms
‚Ä¢	Day 3: Manual tests ‚Äî Dashboard, filtering, feedback
‚Ä¢	Day 4: Admin panel & persistence testing; exploratory
‚Ä¢	Day 5: Accessibility & responsive testing; automated test runs
‚Ä¢	Day 6: Regression re-test & summary report
7. Risk & Mitigation
Risk	Impact	Likelihood	Mitigation
Form validation failures (intentional bug)	High (affects core functionality)	High	Log as P0; create ticket and re-test after fix.
localStorage not updating UI	Medium	Medium	Reproduce steps, capture devtools logs, create issue; consider forced re-render as temp fix.
Missing alt-text in Awareness images	Medium (accessibility)	High	Add alt attributes; add to acceptance criteria.
Cross-browser layout differences	Low‚ÄìMedium	Medium	Test in target browsers; adjust CSS breakpoints.

8. Test Data
Sample Requests (seeded):
‚Ä¢	REQ001 ‚Äî John Doe ‚Äî Nairobi ‚Äî General ‚Äî Preferred: 2025-11-06 ‚Äî Status: Pending
‚Ä¢	REQ002 ‚Äî Jane Smith ‚Äî Kisumu ‚Äî Recyclable ‚Äî Status: Scheduled
‚Ä¢	REQ003 ‚Äî Mike Johnson ‚Äî Mombasa ‚Äî Hazardous ‚Äî Status: Completed
‚Ä¢	REQ004 ‚Äî Sarah Wilson ‚Äî Eldoret ‚Äî General ‚Äî Status: Missed
‚Ä¢	REQ005 ‚Äî David Brown ‚Äî Nairobi ‚Äî Recyclable ‚Äî Status: Pending
User accounts (demo):
‚Ä¢	Regular user: user@cleancity.com / password123
‚Ä¢	Admin user: admin@cleancity.com / admin123
9. Traceability Matrix (Features ‚Üí Test Cases)
Feature	Test Case IDs
Submit pickup request	TC-001, TC-002, TC-003
Filter by location	TC-010, TC-011
Lightbox / images (awareness)	TC-020
Feedback submission & RequestID validation	TC-030, TC-031
Admin status update	TC-040, TC-041
LocalStorage persistence	TC-050
Accessibility (alt text, labels)	TC-060, TC-061
Boundary test (long inputs)	TC-070

10. Test Cases (Key / Required)
Below are sample test cases. Status column is to be filled after execution.
TC-001 ‚Äî Submit valid pickup request (positive)
‚Ä¢	Feature: Request Waste Pickup (Home)
‚Ä¢	Precondition: App open at Home page; logged-in as user (or guest if allowed)
‚Ä¢	Steps:
1.	Navigate to Home ‚Üí Request Waste Pickup form.
2.	Fill "Full Name" = "Alice Tester".
3.	Select Location = "Nairobi".
4.	Select Waste Type = "Recyclable".
5.	Optional: choose preferredDate = (tomorrow).
6.	Click Submit Request.
‚Ä¢	Expected Result: Success message displayed (success-message) and new request added to Dashboard with a new Request ID (REQxxx). localStorage updated with the request.
‚Ä¢	Priority: P0
‚Ä¢	Status: (Pass/Fail)
TC-002 ‚Äî Submit with missing required fields (negative)
‚Ä¢	Feature: Form Validation
‚Ä¢	Steps:
1.	Leave "Full Name" empty.
2.	Click Submit Request.
‚Ä¢	Expected Result: Validation error displayed in name-error element; request is not accepted. (Note known bug: date field may not show validation.)
‚Ä¢	Priority: P0
TC-003 ‚Äî Date validation bug check (intentional)
‚Ä¢	Feature: Date validation
‚Ä¢	Steps:
1.	In form, leave other required fields valid but input invalid past date or empty date if the requirement expects a date ‚Äî exercise the known bug.
‚Ä¢	Expected Result: According to spec, date is optional, but known bug: "date field doesn't show validation error" ‚Äî log behavior as observed.
‚Ä¢	Priority: P1
TC-010 ‚Äî Filter by location (Eldoret)
‚Ä¢	Feature: Dashboard filtering
‚Ä¢	Steps:
1.	Go to Dashboard.
2.	Set locationFilter to "Eldoret".
‚Ä¢	Expected Result: Only requests with Location = Eldoret are displayed. (Known bug: currently shows Nairobi; log if reproduced.)
‚Ä¢	Priority: P0
TC-020 ‚Äî Awareness images accessibility
‚Ä¢	Feature: Awareness page images
‚Ä¢	Steps:
1.	Open Awareness page.
2.	Inspect images for alt attribute.
3.	Use a screen reader or Lighthouse to check image accessibility.
‚Ä¢	Expected Result: Each image has an appropriate alt attribute. (Known bug: Missing alt-text on images.)
‚Ä¢	Priority: P1
TC-030 ‚Äî Feedback: invalid Request ID
‚Ä¢	Feature: Feedback form
‚Ä¢	Steps:
1.	Enter requestId = "REQ999" (non-existent).
2.	Select reason and submit.
‚Ä¢	Expected Result: Validation error requestId-error shown indicating invalid request ID.
‚Ä¢	Priority: P1
TC-040 ‚Äî Admin: mark as Scheduled and UI update
‚Ä¢	Feature: Admin status updates
‚Ä¢	Steps:
1.	Login as admin.
2.	Navigate to Admin ‚Üí select REQ001 ‚Üí choose "Scheduled" ‚Üí click Update.
‚Ä¢	Expected Result: Request status updates in admin table and dashboard; localStorage updated; UI refreshes immediately. (Known bug: UI doesn't refresh.)
‚Ä¢	Priority: P0
TC-050 ‚Äî LocalStorage persistence
‚Ä¢	Feature: Data persistence
‚Ä¢	Steps:
1.	Submit a request.
2.	Open devtools ‚Üí Application ‚Üí localStorage ‚Üí verify new entry.
3.	Reload page and check request still listed.
‚Ä¢	Expected Result: data persisted across reloads.
‚Ä¢	Priority: P1
TC-070 ‚Äî Boundary testing: very long input
‚Ä¢	Feature: Boundary testing
‚Ä¢	Steps:
1.	In Full Name, enter 5,000 characters.
2.	Submit the form.
‚Ä¢	Expected Result: Application handles gracefully ‚Äî truncated or rejected with a validation message; layout not broken. If layout breaks, record as bug.
‚Ä¢	Priority: P2
11. Automated Tests
Recommended automated tests to implement with React Testing Library:
‚Ä¢	Render pickup form and assert required fields and error messages (TC-001, TC-002).
‚Ä¢	Simulate filter controls on dashboard and assert filtered output (TC-010).
‚Ä¢	Test admin status update function updates storage and returns expected data (TC-040).
‚Ä¢	Snapshot tests for major components (home, dashboard, admin) to catch UI regressions.
Example Jest test skeleton:
// sample: PickupForm.test.js
import { render, screen, fireEvent } from '@testing-library/react';
import PickupForm from '../PickupForm';

test('shows error when full name is empty', () => {
  render(<PickupForm />);
  fireEvent.click(screen.getByText(/Submit Request/i));
  expect(screen.getByText(/required/i)).toBeInTheDocument();
});
Run with: npm test
12. Defect Reporting & Management
Tool: Use GitHub Issues and Jira. Each defect should include:
‚Ä¢	Title (clear short summary)
‚Ä¢	Description (steps to reproduce, expected vs actual)
‚Ä¢	Environment (browser, OS, app version)
‚Ä¢	Severity (P0/P1/P2)
‚Ä¢	Attachments (screenshots, console logs)
‚Ä¢	Assignee & label (bug/UX/accessibility)
Severity Definitions:
‚Ä¢	P0 (Critical): Core functionality broken (submit request fails, filter returns wrong dataset). Blocker for release.
‚Ä¢	P1 (High): Important features affected or major UX problems (missing alt text, persistence issues).
‚Ä¢	P2 (Medium): Nice-to-have fixes or cosmetic issues (layout quirks).
‚Ä¢	P3 (Low): Low impact, suggestions.
________________________________________
13. Test Metrics & Reporting
Metrics to gather:
‚Ä¢	Number of test cases executed / passed / failed
‚Ä¢	Number of defects opened / closed (by severity)
‚Ä¢	Test coverage reported by Jest (if configured)
‚Ä¢	Accessibility score from Lighthouse
Test Status Reporting:
‚Ä¢	Daily standup summary (what tested, top issues)
‚Ä¢	End-of-cycle test summary with pass rate, major defects, and recommendations
14. Sign-off Criteria
Project is ready for sign-off when:
‚Ä¢	All P0 defects resolved and verified.
‚Ä¢	90%+ of planned test cases executed.
‚Ä¢	Test summary and defect list provided to stakeholders.
Team Roles (3 teammates)
Role	Responsibilities		Deliverables
Test Manager	  Plan, coordinate, finalize  report		Updated Test Plan, daily status reports, final Test Summary.
Risk Analyst	  Identify,log & monitor risks		Risk register, impact analysis, mitigation recommendations.

Test Executor	    Run tests & report bugs		Test execution evidence (screenshots, logs), defect tickets, test case status updates.
Communication Plan
Primary Channels:
‚Ä¢	Jira / Google Meet / WhatsApp: real-time collaboration & quick questions 
‚Ä¢	GitHub Issues: defect tracking and detailed bug reports.
‚Ä¢	Email: official sign-offs / final report submission.
‚Ä¢	Google Drive / Repo: share test artifacts (test case spreadsheets, screenshots).
Meeting Cadence:
‚Ä¢	Daily Standup: 10‚Äì15 minutes ‚Äî each teammate reports what they did, plan, and blockers.
‚Ä¢	Mid-sprint Review: (halfway through testing) ‚Äî 30 minutes to review defect trends.
‚Ä¢	Final Sign-off Meeting: 30 minutes ‚Äî present test summary & sign-off.
Reporting Cadence:
‚Ä¢	Daily: Quick status in channel (test progress, blockers).
‚Ä¢	End-of-day: Short email or GitHub comment summarizing major findings.
‚Ä¢	End-of-cycle: Full Test Summary (test execution, defects, coverage, recommendations).
Escalation Path:
1.	Test Executor ‚Üí Test Manager (for issues that block test progress)
2.	Test Manager ‚Üí Instructor / Stakeholder (for unresolved P0 issues)
Templates:
‚Ä¢	Daily Standup Message Example:
o	Completed: Executed test cases 
o	In progress: Accessibility checks 
o	Blocker: Unable to reproduce admin UI refresh bug on Chrome
‚Ä¢	GitHub Issue Template:
o	Title: Filter by location returns wrong results (Eldoret shows Nairobi)
o	Steps to Reproduce: ‚Ä¶
o	Expected Behavior: ‚Ä¶
o	Actual Behavior: ‚Ä¶
o	Environment: Chrome 118 on Windows 10
o	Attachments: screenshot.png
o	Assignee: @member
Quick Checklist Before Execution
‚Ä¢ Confirm the project runs locally with npm start.
‚Ä¢ Verify seed data (REQ001‚ÄìREQ005) present.
‚Ä¢ Create repository folder for test artifacts.
‚Ä¢ Prepare test cases in a spreadsheet or Markdown for execution tracking.
‚Ä¢ Create Issues


---
## 4. Test Approach
- **Testing Type:** Manual Functional Testing  
- **Environment:** Chrome v120 on Windows 10  
- **Method:** Exploratory and scenario-based  
- **Focus Areas:** Form validation, navigation, authentication, and layout consistency

---


## 6. Key Defects Summary
- Event filtering not functional.
- Minor alignment issues on small screens.
- Missing profile edit feature.
- Missing accessibility attributes.

---

## Risks & Recommendations
### Risks:
- Missing validation may allow incomplete data submission.
- Poor mobile optimization can affect usability.

### Recommendations:
- Implement backend validation.
- Improve mobile CSS layout.
- Add ‚ÄúProfile Edit‚Äù and event filtering.
- Conduct accessibility testing (WCAG 2.1).

---

## Conclusion
Overall, the Clean City Project performs well functionally with strong user experience and stability. Most modules are fully operational. Minor UX and responsive issues can be addressed in future iterations.


**Test Manager:** _MERCY CHEBET____________  
**Approved By:** __HORACE WITABA, EMILY AWUOR_____________  
**Date:** ___13/11/2025________________


